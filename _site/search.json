{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "This will be a description of me and my journey up to this point. Initially I thought this would be a quick little write up, but I've realized that it will take a bit more reflecting. This realization came about after completeing the \"personal brand\" session from the U of T tutorial. ( Include most of this in reflection piece). Talk about having \"filler content\" in there, but didn't feel right putting in and decided to leave open.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nHeading 1\r\nHeading 2\r\nHeading 3\r\n\r\nHeading 1\r\nHeading 2\r\nHeading 3\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-29T20:19:17-04:00"
    },
    {
      "path": "CV.html",
      "title": "CV",
      "author": [],
      "contents": "\r\n\r\nContents\r\nEducation\r\nExperience\r\n\r\nEducation\r\nUniversity of Toronto | Toronto, Canada\r\nB.Sc - Specialist in Statistics with Major in Mathematics | 2017 - 2023 (anticipated)\r\nExperience\r\nPureFacts Financial Solutions| Quality Assurance - Tester | 2016 - 2018\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-29T20:19:21-04:00"
    },
    {
      "path": "index.html",
      "title": "St. Clair Pennyfeather",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Saint's Space\r\n          \r\n          \r\n          Home\r\n          About\r\n          CV\r\n          Research\r\n          Projects\r\n          Musings\r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              St. Clair Pennyfeather\r\n            \r\n            \r\n              \r\n                \r\n                    \r\n                      \r\n                        \r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        \r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        \r\n                      \r\n                    \r\n                  \r\n                                  \r\n            \r\n          \r\n        \r\n        \r\n        \r\n          \r\n            \r\n            A Statistician……….\r\n            Who loves  for saving me from pen & paper calculations……\r\n            and the pain that would ensue if you forgot to carry that extra 1….\r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              St. Clair Pennyfeather\r\n            \r\n            \r\n              \r\n                \r\n                                    \r\n                    \r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                    \r\n                  \r\n                                  \r\n              \r\n            \r\n            \r\n              \r\n              A Statistician……….\r\n              Who loves  for saving me from pen & paper calculations……\r\n              and the pain that would ensue if you forgot to carry that extra 1….\r\n              \r\n            \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    \r\n      © 2022 St. Clair Pennyfeather\r\n      Made with  distill package.\r\n      Distill is a publication format for scientific and technical writing, native to the web.\r\n      Learn more about using Distill for R Markdown at https://rstudio.github.io/distill.\r\n      Last updated on March 30, 2022\r\n      \r\n      \r\n\r\n  \r\n  ",
      "last_modified": "2022-03-29T20:19:22-04:00"
    },
    {
      "path": "Musings.html",
      "title": "Musings",
      "description": "The stream of conciousness.....of Mr S. Pennyfeather.\n",
      "author": [],
      "contents": "\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-29T20:19:27-04:00"
    },
    {
      "path": "Projects.html",
      "title": "Projects",
      "description": "This section contains previous academic assignments that I did in previous courses at the insitutions I've attended. Each post will contain an initial description of the course that the project was for, what the assignment guidelines were, and finally the presentation of the assignment itself.  \n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nDisclaimer\r\nIntroduction\r\nStatistical skills sample\r\nSetting up libraries\r\nVisualizing the variance of a Binomial random variable for varying proportions\r\nDemonstrating frequentist confidence intervals as long-run probabilities of capturing a population parameter\r\nInvestigating whether there is an association between cGPA and STA303/1002 students correctly answering a question on global poverty rates\r\nGoal\r\nWrangling the data\r\nVisualizing the data\r\nTesting\r\n\r\n\r\nWriting sample\r\nIntroduction\r\nSoft skills\r\nAnalytic skills\r\nConnection to studies\r\nConclusion\r\n\r\nReflection\r\nWhat is something specific that I am proud of in this mini-portfolio?\r\nHow might I apply what I’ve learned and demonstrated in this mini-portfolio in future work and study, after STA303/1002?\r\nWhat is something I’d do differently next time?\r\n\r\n\r\nDisclaimer\r\nFor the moment I will only include the mini - portfolio assignment as a presentation, but after some research I feel that using a blog format will allow me include assignments in a more organized fashion. I also have to figure out how to customize headers for individual assignments, but I think that may be solved once I use thee blog format for this part of my site. I have yet to figure out how to include blogs properly in my site. This will come soon.\r\n\r\nIntroduction\r\nThe preparation of this mini-portfolio has served as an introduction of the level of proficiency that one requires to be a professional in the world of statistics. Up to this point in my journey in the world of statistics, all the skills that I’ve developed have been strictly technical with not much context of their applicability. This mini-portfolio has brought awareness of how these things all interact. Applying technical skills such as performing simple hypothesis tests, analyzing the test’s results, and drawing inferences from those results. Writing about the results in a manner that is understandable for your given audience. Creating visualizations through the use of the ggplot2 package to communicate the ideas of the techincal results in a manner that can create understanding for stakeholders. All these different skills were applied while composing this mini-portfolio. Providing a first look at the various facets of one’s overall development that may need to be polished up when the time arrives to apply for a job or grad school.\r\n\r\nStatistical skills sample\r\nSetting up libraries\r\n\r\n\r\n# Reading the necessary R libraries into R Studio to be able to perform analysis\r\nlibrary(tidyverse)\r\nlibrary(readxl)\r\nlibrary(janitor)\r\n\r\n\r\n\r\nVisualizing the variance of a Binomial random variable for varying proportions\r\n\r\n\r\nn1 = 30\r\nn2 = 400\r\n\r\nprops = seq(from = 0, to = 1, by = 0.01)\r\n\r\n# initialized two vectors to populate with \r\n\r\nn1_var = vector(mode = \"numeric\", length = length(props))\r\nn2_var = vector(mode = \"numeric\", length = length(props))\r\n\r\n\r\n# populated vector of variances using for-loop\r\n\r\nfor(i in 1:length(props)){\r\n  \r\n  n1_var[i] = n1 * props[i] * (1 - props[i])\r\n  n2_var[i] = n2 * props[i] * (1 - props[i])\r\n  \r\n}\r\n\r\n\r\nfor_plot = tibble(\"props\" = props, \"var_of_n1\" = n1_var, \"var_of_n2\" = n2_var)\r\n\r\n# plotting of graph n1\r\n\r\ngraph_for_n1 = for_plot %>% ggplot(mapping = aes(x = props, y = var_of_n1)) + geom_point() + theme_minimal() + \r\n  labs(x =\"Proportions\", y = \"Var of n1\", title = str_c(\"Variance of Binomial RV with n1 = \", n1), caption = \"Created by St. Clair Pennyfeather\")\r\ngraph_for_n1\r\n\r\n\r\n\r\n\r\nFigure 1: Proportion tending to 0.50 for n1 = 30\r\n\r\n\r\n\r\n\r\n\r\n# plotting of graph n2\r\n\r\ngraph_for_n2 = for_plot %>% ggplot(mapping = aes(x = props, y = var_of_n2)) + geom_point() + theme_minimal() + \r\n  labs(x =\"Proportions\", y = \"Var of n2\", title = str_c(\"Variance of Binomial RV with n2 = \", n2), caption = \"Created by St. Clair Pennyfeather\")\r\ngraph_for_n2\r\n\r\n\r\n\r\n\r\nFigure 2: Proportion tending to 0.50 for n2 = 400\r\n\r\n\r\n\r\n\r\nDemonstrating frequentist confidence intervals as long-run probabilities of capturing a population parameter\r\n\r\n\r\nset.seed(716)\r\n\r\nsim_mean = 10\r\nsim_sd = 2\r\nsample_size = 30\r\nnumber_of_samples = 100\r\ndeg_free = sample_size - 1\r\n\r\n\r\ntmult = qt(p = 1 - 0.05/2, df = deg_free)\r\n\r\npopulation = rnorm(n = 1000, mean = sim_mean, sd = sim_sd)\r\n\r\npop_param = mean(population)\r\n\r\n# Getting 100 samples of size 30, had to unlist in order to use as a vector\r\n\r\nsample_set = unlist(lapply(1:number_of_samples,\r\n                            function (x) sample(population, size = sample_size)))\r\n\r\ngroup_id = rep(x = 1:number_of_samples, each = sample_size)\r\n\r\n# Creation of tibble to input the observations\r\n\r\nmy_sim = tibble(\"group_id\" = group_id, \"sample_set\" = sample_set)\r\n\r\nci_vals = tibble( my_sim %>% group_by(group_id) %>% summarise(mean = mean(sample_set), sd =  sd(sample_set)))\r\n\r\nlower = vector(length = number_of_samples)\r\nupper = vector(length = number_of_samples)\r\ncapture = vector(length = number_of_samples)\r\n\r\n# Had to initilaize the columns of tibble with NA values, this is due to a bug \r\n#in the tibble package with regards to populating the data set\r\nci_vals$lower = NA\r\nci_vals$upper = NA\r\nci_vals$capture = NA\r\n\r\n# Populated tibble with values for the confidence intervals\r\n\r\nfor(i in 1:number_of_samples){\r\n  \r\nci_vals$lower[i] = ci_vals$mean[i]  - tmult*(ci_vals$sd[i]/sqrt(sample_size))\r\nci_vals$upper[i] = ci_vals$mean[i]  + tmult*(ci_vals$sd[i]/sqrt(sample_size))\r\nci_vals$capture[i] = ((ci_vals$lower[i] <= pop_param) & (pop_param <= ci_vals$upper[i]))\r\n  }\r\n\r\n\r\nproportion_capture = sum(ci_vals$capture == TRUE)/number_of_samples\r\n\r\n# Visualization of the confidence intervals for our approximation to the population mean\r\n\r\nconfid_ints = ggplot(data = ci_vals, mapping = aes(x =group_id , y = mean , ymin = lower, ymax = upper, color = capture)) + \r\n  geom_point() + geom_errorbar() + geom_hline(mapping = aes(yintercept = pop_param), linetype = 2) + \r\n  scale_color_manual(name = \"CI captures population\\n parameter\" ,values = c(\"#B80000\", \"#122451\")) + coord_flip() + theme_minimal() + \r\n  theme(legend.key.width = unit(x = 1, units = \"cm\"), legend.title = element_text(size = 10)) + labs(x = \"Means\", y = \"Group ID\", \r\n  title = str_c(\"CI Plot for Estimation of Mean based on N~(\", sim_mean,\",\",sim_sd,\")\"), \r\n  caption = \"Created by St. Clair Pennyfeather in STA303/1002, Winter 2022\")\r\n\r\nconfid_ints\r\n\r\n\r\n\r\n\r\nFigure 3: Exploring our long-run ‘confidence’ in confidence intervals. This figure shows how often 95% confidence intervals from 100 simple random samples capture the population mean. The population was simulated from N(10, 2)\r\n\r\n\r\n\r\n97 % of my intervals capture the the population parameter.\r\nIn our plot observe that we have calculated the mean value of our population as 10.055. We do this because this serves as an illustration of the theory that statisticians use in practice (i.e the real world). By performing a simulation we hope to illustrate what it is we are attempting to accomplish on a larger scale. In the real world it is very unlikely that we will know what the mean of the population really is, but we can estimate it. This estimating is done through a series of sampling procedures. With these estimations of the population mean we create confidence intervals which serve to measure the level of uncertainty we have in our estimation of the population mean. Our aim is to accurately measure the population mean which we hope we have done through our array of techniques. But recall this is only an estimate of the TRUE population mean. We cannot get the true population mean because it would require recording a measurement for every single unit in the population which is not feasible to do based on the sizes of populations. But for illustration of how we go about this we can perform a simulation and form there extrapolate.\r\nInvestigating whether there is an association between cGPA and STA303/1002 students correctly answering a question on global poverty rates\r\nGoal\r\nOur goal is to see if we can infer that a person’s cGPA is enough to determine if the student got the correct answer on our survey.\r\nWrangling the data\r\n\r\n\r\ncgpa_data = \r\n  read_excel(\"C:/Users/Saint/Documents/School_2017_onward/2021-2022/STA303/Mini_Portfolio_1/sta303-w22-mini-portfolio/sta303-w22-mini-portfolio/data/sta303-mini-portfolio-poverty.xlsx\")\r\n\r\ncgpa_data =  clean_names(dat = cgpa_data)\r\n\r\ncgpa_data =  cgpa_data %>% \r\n  rename(global_poverty_ans = in_the_last_20_years_the_proportion_of_the_world_population_living_in_extreme_poverty_has, \r\n              cgpa = what_is_your_c_gpa_at_u_of_t_if_you_dont_want_to_answer_you_can_put_a_0)\r\n\r\n# filtering of data to include only cGPA values that make sense.\r\n\r\ncgpa_data = cgpa_data %>% filter(is.na(cgpa) != TRUE, cgpa < 4.1) %>% mutate(correct = (global_poverty_ans == 'Halved')) \r\n\r\n\r\n\r\nVisualizing the data\r\n\r\n\r\n# Graphing of the cGPA data\r\n\r\ncgpa_data %>% group_by(correct) %>%  ggplot(mapping = aes(x = cgpa,color = \"red\", fill = cgpa)) + geom_histogram(bins = 25) + facet_wrap(facets = vars(correct), nrow = 2) + \r\n  labs(x = \"cgpa\", title = \"Distributions of cgpa by TRUE/FALSE\")\r\n\r\n\r\n\r\n\r\nTesting\r\nThe tests that were performed were a two sided paired t-test along with a Wilcoxon paired test (also known as Mann-Whitney U). The decision to perform the t-test is down to the objective of our test which is to determine a difference in means between groups in our sample. We are doing this based on the assumption that our whole sample came from a normally distributed population. . In this case the population of cGPAs. But since we cannot be sure that our assumption of normality is going to be able to hold we perform a non-parametric test, which in this case is the Wilcoxon paired test. Based on the visualization of the distribution of our data we may think that the population is not normally distributed, but this possible flaw in the visualization is due to the choice of s subset of the sample to not disclose one’s cGPA. Keeping this in mind this is why we also perform the Wicoxon test\r\n\r\n\r\n# created filtered data frames to differentiate the two groups under consideration\r\n\r\ntrue_vector = cgpa_data %>% filter(correct == TRUE)\r\nfalse_vector = cgpa_data %>% filter(correct != TRUE)\r\n\r\n#performed various tests and confirmed them through use of the lm() model\r\n\r\nsigned_rank = function(x){ sign(x) * rank(abs(x))} # to be used in the lm() model\r\n\r\nt.test(x = true_vector$cgpa, y = false_vector$cgpa, mu = 0, var.equal = TRUE, paired = TRUE)\r\n\r\n\r\n\r\n    Paired t-test\r\n\r\ndata:  true_vector$cgpa and false_vector$cgpa\r\nt = 1.2218, df = 98, p-value = 0.2247\r\nalternative hypothesis: true difference in means is not equal to 0\r\n95 percent confidence interval:\r\n -0.1906653  0.8015764\r\nsample estimates:\r\nmean of the differences \r\n              0.3054556 \r\n\r\nt.test(formula = cgpa ~ correct  , mu = 0, var.equal = TRUE, paired = TRUE, data = cgpa_data)\r\n\r\n\r\n\r\n    Paired t-test\r\n\r\ndata:  cgpa by correct\r\nt = -1.2218, df = 98, p-value = 0.2247\r\nalternative hypothesis: true difference in means is not equal to 0\r\n95 percent confidence interval:\r\n -0.8015764  0.1906653\r\nsample estimates:\r\nmean of the differences \r\n             -0.3054556 \r\n\r\nbinded_col = bind_cols(true_vector, false_vector, .name_repair = \"unique\") # in order to compare differences using an lm() model I had to put the two groupings \r\n# in a data set organized by whether they answered TRUE or FALSE.\r\n\r\nlm_of_cgpa_mean_diff = lm(formula = (binded_col$cgpa...3 - binded_col$cgpa...7) ~ 1, data = binded_col)\r\n\r\nsummary(lm_of_cgpa_mean_diff)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = (binded_col$cgpa...3 - binded_col$cgpa...7) ~ 1, \r\n    data = binded_col)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n-4.3055 -1.0055 -0.1355  2.4945  3.6945 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)\r\n(Intercept)   0.3055     0.2500   1.222    0.225\r\n\r\nResidual standard error: 2.487 on 98 degrees of freedom\r\n\r\n# Non parametric comparison of the difference in means\r\nwilcox.test(formula = cgpa ~ correct, mu = 0, paired = TRUE, data = cgpa_data)\r\n\r\n\r\n\r\n    Wilcoxon signed rank test with continuity correction\r\n\r\ndata:  cgpa by correct\r\nV = 1683, p-value = 0.1918\r\nalternative hypothesis: true location shift is not equal to 0\r\n\r\nlm_of_cgpa_mean_diff_np = lm(signed_rank(true_vector$cgpa - false_vector$cgpa) ~ 1)\r\n\r\nsummary(lm_of_cgpa_mean_diff_np)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = signed_rank(true_vector$cgpa - false_vector$cgpa) ~ \r\n    1)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n-106.47  -45.97    9.03   47.53   90.53 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)\r\n(Intercept)    7.970      5.758   1.384    0.169\r\n\r\nResidual standard error: 57.29 on 98 degrees of freedom\r\n\r\nFrom the outputs that the various tests produced we see that the assumption of normality does indeed hold. This is shown through comparing the p-values between the parametric t-tests and the non-parametric west (Wilcoxon), which produce p-values of 0.225 and 0.1918 respectively. To verify these results we performed linear regressions to approximate the difference in means. These provided values of 0.225 and 0.137 for the parametric and non-parametric cases respectively. From these summaries we have no evidence to reject the null hypothesis assumption of there being a difference in the mean cGPA between people who answered correct and incorrect on the survey.\r\n\r\nWriting sample\r\nIntroduction\r\nTo obtain any level of success today in the professional world, one needs to equip themselves with an array of skill sets. One way to categorize the different skill sets is by soft skills and analytic skills. Soft skills can be seen as personality traits which characterize one’s relationship in a social environment. In comparison analytic skills would be those that are specific to individual professions and more technical. What follows is a description of the skills which would allow me to contribute to the larger goals of the institution. Followed by skills working for this institution would allow me to develop.\r\nSoft skills\r\nCommunication skills are seen as a necessary skill set in order to be able to be seen as a potential candidate. The need for communication skills can be seen through the example of collaboration. These projects are large and cannot be done by one individual. As such the requirement to be able to communicate and get along with people from different backgrounds is necessary in order to hit targets. Being able to demonstrate accountability and ownership of projects are signs of leadership being illustrated. All leadership does not have to be from purely motivational speeches, but also the actions that follow those speeches. By owning a project from start to finish one shows the ability to lead and take control when necessary. These two skills are ones that are ones that are looked for by Yelp in order to drive their business forward.\r\nAnalytic skills\r\nCritical thinking is one of the most sought after analytical skills. It is with critical thinking that one is able to understand and extrapolate on statistical inferences and analyses. Critical thinking allows one to deconstruct problems in a structured way and develop solutions. It is not explicitly stated in the job posting, but the requirement for solid understanding in statistical practices is one example of Yelp’s desire for critical thinkers. Creativity is another skill that is desired in the job description. This can be seen in the request to have the ability to design statistical models. Another place this is shown is in defining the key performance metrics that Yelp would use in the future.\r\nConnection to studies\r\nEducation doesn’t end after acquiring a professional designation. As such the opportunities are endless. As such there are always areas to improve on. One can take writing courses to be a better written communicator, presentation courses if there is a weakness in vocal communication. If the skills that one wants to work on are more technical, there are advanced stats courses one can take. One can also learn new software languages such as SQL. Graduate school is another option for those inclined.\r\nConclusion\r\nThe soft skills of communication and leadership along with the analytical skills of critical thinking and creativity provide a solid foundation upon which one would be able to feel comfortable in the applicant pool for a position like the one being offered by Yelp. Beyond Yelp the opportunities to further one’s skills does not end once a formal degree is acquired.\r\nWord count: 517 words (counting headers)\r\n\r\nReflection\r\nWhat is something specific that I am proud of in this mini-portfolio?\r\nOne of the things I’m proud of in this mini portfolio was being able to digest what was requested of me in each of the tasks and formulate a course of action by applying the techniques and skills I had learned in previous courses. I had a rough time in my lower years stats courses and needed to take time off to strengthen my foundations. It’s a good feeling to see that that work has reaped results in just my overall ability to process the whole picture. Without the need to continuously go back to review what “this” or “that” concept was about I was able to focus on the analysis at hand.\r\nHow might I apply what I’ve learned and demonstrated in this mini-portfolio in future work and study, after STA303/1002?\r\nThe importance of visualizations to be able to give yourself a clearer “picture” of what may be happening in your data. Using the tidyverse tools allows us to have a grounding in being able to convey ideas in an easier to comprehend way. An example of where this would come in handy is should the situation arise that I need to provide a summary of a certain measurement, such as the mean, to a group of stakeholders. They may not understand all of the machinery under the hood when it comes to presenting results, but a nice picture of the confidence intervals and an explanation of them may help to provide understanding. Another skill that can be applied in future will be thethought process needed to considered which statistical tests one chooses to use.\r\nWhat is something I’d do differently next time?\r\nIn the realm of doing things different, I would say beginning the assignment earlier by incorporating it into the time I allocate to readings. To at least have an idea of what the questions are asking and how what I’m reading at the current time can be applied to solving the task. I have the practice of wanting to finish all my readings first and then begin any exercises. But perhaps that is going to have to change to be more efficient and prevent the need for putting off other parts of my life at the expense of rushing to finish an assignment on time. Also allowing time to properly proofread my work.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-29T20:20:04-04:00"
    },
    {
      "path": "Research.html",
      "title": "Research",
      "description": "Area will include any research assignments I have been a part of. At the start of each assignment I will have an explanation of what part I contributed. May set this page up as a colletion of hyperlinked citations to places where the research may be found.",
      "author": [],
      "contents": "\r\n\r\nContents\r\nPaper 1\r\nPaper 2\r\nPaper 3\r\n\r\nPaper 1\r\nDescription\r\nPaper 2\r\nDescription\r\nPaper 3\r\nDescription\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-29T20:20:09-04:00"
    }
  ],
  "collections": []
}
